{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04wWdwq5xoDd",
        "outputId": "6d00381b-760c-4fc4-8d70-2ad94dc514b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gitpython\n",
            "  Downloading GitPython-3.1.41-py3-none-any.whl (196 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/196.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m194.6/196.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1 (from gitpython)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/62.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, gitdb, gitpython\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.41 smmap-5.0.1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<git.repo.base.Repo '/content/m1_repo/.git'>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "#install this if you do not have this already installed\n",
        "!pip install gitpython\n",
        "\n",
        "import git\n",
        "import sys\n",
        "\n",
        "\n",
        "# Clone the GitHub repository\n",
        "repo_url = 'https://github.com/Natural-Language-Processing-YU/Module-1-Assignment.git'\n",
        "repo_dir = '/content/m1_repo'  # Specify the directory to clone the repository\n",
        "git.Repo.clone_from(repo_url, repo_dir)\n",
        "# Add the cloned repository directory to the import path"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#extract the tweets\n",
        "import pandas as pd\n",
        "\n",
        "tweets = pd.read_csv('/content/m1_repo/data/elonmusk_tweets.csv') #import file\n",
        "print(tweets.dtypes) #print data types\n",
        "print(tweets.text) #show tweets from file\n",
        "df = pd.DataFrame(tweets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79DhMZ4Qx1hU",
        "outputId": "14f5e3a1-f430-44cf-86eb-fe17ce6d58f4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id             int64\n",
            "created_at    object\n",
            "text          object\n",
            "dtype: object\n",
            "0       b'And so the robots spared humanity ... https:...\n",
            "1       b\"@ForIn2020 @waltmossberg @mims @defcon_5 Exa...\n",
            "2           b'@waltmossberg @mims @defcon_5 Et tu, Walt?'\n",
            "3                     b'Stormy weather in Shortville ...'\n",
            "4       b\"@DaveLeeBBC @verge Coal is dying due to nat ...\n",
            "                              ...                        \n",
            "2814                 b'That was a total non sequitur btw'\n",
            "2815    b'Great Voltaire quote, arguably better than T...\n",
            "2816    b'I made the volume on the Model S http://t.co...\n",
            "2817    b\"Went to Iceland on Sat to ride bumper cars o...\n",
            "2818    b'Please ignore prior tweets, as that was some...\n",
            "Name: text, Length: 2819, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk                                # Python library for NLP\n",
        "import re                                  # library for regular expression operations\n",
        "import string                              # for string operations\n",
        "\n",
        "from nltk.corpus import stopwords          # module for stop words that come with NLTK\n",
        "from nltk.stem import PorterStemmer        # module for stemming\n",
        "from nltk.tokenize import TweetTokenizer   # module for tokenizing strings\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def clean_tweet(tweet_text):\n",
        "    \"\"\"\n",
        "    Function to process the text of a tweet: cleaning, tokenizing, removing stopwords, and stemming.\n",
        "    Args:\n",
        "    tweet_text: A string containing the tweet's text.\n",
        "\n",
        "    Returns:\n",
        "    list: A list of words after processing.\n",
        "    \"\"\"\n",
        "    # Eliminate URLs\n",
        "    tweet_text = re.sub(r'https?://\\S+', '', tweet_text)\n",
        "\n",
        "    # Strip out hashtag symbols\n",
        "    tweet_text = re.sub(r'#', '', tweet_text)\n",
        "\n",
        "    # Remove the leading byte order mark if present\n",
        "    tweet_text = re.sub(r\"^\\s*b'\", '', tweet_text)\n",
        "\n",
        "    # Tokenize the tweet text using TweetTokenizer\n",
        "    tweet_tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
        "    tokenized_tweet = tweet_tokenizer.tokenize(tweet_text)\n",
        "\n",
        "    # Filter out stopwords and punctuation\n",
        "    english_stopwords = stopwords.words('english')\n",
        "    filtered_tweet = [term for term in tokenized_tweet if term not in english_stopwords and term not in string.punctuation]\n",
        "\n",
        "    # Apply stemming to the filtered tweet\n",
        "    stemmer = PorterStemmer()\n",
        "    stemmed_tweet = [stemmer.stem(word) for word in filtered_tweet]\n",
        "\n",
        "    return stemmed_tweet\n",
        "\n",
        "# Load the dataset containing tweets\n",
        "tweets_df = pd.read_csv('/content/m1_repo/data/elonmusk_tweets.csv')\n",
        "\n",
        "# Apply preprocessing to each tweet in the dataframe\n",
        "tweets_df['preprocessed_tweet'] = tweets_df['text'].apply(clean_tweet)\n",
        "\n",
        "# Display the first few rows of original and preprocessed tweets\n",
        "print(tweets_df[['text', 'preprocessed_tweet']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MR2grRnnyg7p",
        "outputId": "535a52b2-2569-487e-92bf-8480f30cfb2e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text  \\\n",
            "0  b'And so the robots spared humanity ... https:...   \n",
            "1  b\"@ForIn2020 @waltmossberg @mims @defcon_5 Exa...   \n",
            "2      b'@waltmossberg @mims @defcon_5 Et tu, Walt?'   \n",
            "3                b'Stormy weather in Shortville ...'   \n",
            "4  b\"@DaveLeeBBC @verge Coal is dying due to nat ...   \n",
            "\n",
            "                                  preprocessed_tweet  \n",
            "0                         [robot, spare, human, ...]  \n",
            "1  [b, exactli, tesla, absurdli, overvalu, base, ...  \n",
            "2                                     [et, tu, walt]  \n",
            "3                   [stormi, weather, shortvil, ...]  \n",
            "4   [b, coal, die, due, nat, ga, frack, basic, dead]  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to compute the Levenshtein distance utilizing dynamic programming\n",
        "def compute_levenshtein_distance(str1, str2):\n",
        "    \"\"\"\n",
        "    Compute the Levenshtein distance, which is a measure of the difference between two sequences.\n",
        "    Args:\n",
        "    str1: First string for comparison.\n",
        "    str2: Second string for comparison.\n",
        "\n",
        "    Returns:\n",
        "    int: The Levenshtein distance between str1 and str2.\n",
        "    \"\"\"\n",
        "    # Initializing the matrix dimensions\n",
        "    len_str1, len_str2 = len(str1), len(str2)\n",
        "    distance_matrix = [[0] * (len_str2 + 1) for _ in range(len_str1 + 1)]\n",
        "\n",
        "    # Populating the matrix with dynamic programming\n",
        "    for x in range(len_str1 + 1):\n",
        "        for y in range(len_str2 + 1):\n",
        "            if x == 0:\n",
        "                distance_matrix[x][y] = y\n",
        "            elif y == 0:\n",
        "                distance_matrix[x][y] = x\n",
        "            elif str1[x - 1] == str2[y - 1]:\n",
        "                distance_matrix[x][y] = distance_matrix[x - 1][y - 1]\n",
        "            else:\n",
        "                distance_matrix[x][y] = 1 + min(distance_matrix[x - 1][y],    # Deletion\n",
        "                                                distance_matrix[x][y - 1],    # Insertion\n",
        "                                                distance_matrix[x - 1][y - 1])  # Substitution\n",
        "\n",
        "    return distance_matrix[len_str1][len_str2]\n",
        "\n",
        "# Example usage of the function\n",
        "first_string = 'stemming'\n",
        "second_string = 'lemmatization'\n",
        "distance = compute_levenshtein_distance(first_string, second_string)\n",
        "print(f\"The Levenshtein Distance is: {distance}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyZNWIuT3CyK",
        "outputId": "5771b692-231f-462b-eec4-043a185fac13"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Levenshtein Distance is: 10\n"
          ]
        }
      ]
    }
  ]
}